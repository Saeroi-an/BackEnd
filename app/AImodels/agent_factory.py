# app/AImodels/agent_factory.py
"""
Agent Factory Module
LLMê³¼ Toolì„ ì „ì—­ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ê³ , ì„¸ì…˜ë³„ Agent Executorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""
from langchain_community.llms import HuggingFaceEndpoint
from langchain.agents import AgentExecutor, create_react_agent
from langchain.memory import ConversationBufferMemory
from langchain import hub
import os
import logging

from app.AImodels.tools import ALL_TOOLS

logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
HUGGINGFACE_TOKEN = os.getenv('HUGGINGFACE_TOKEN', '')
REPO_ID = os.getenv('LLM_REPO_ID', 'google/flan-t5-large')

logger.info(f"ðŸ” HUGGINGFACE_TOKEN ê¸¸ì´: {len(HUGGINGFACE_TOKEN) if HUGGINGFACE_TOKEN else 0}")
logger.info(f"ðŸ” LLM_REPO_ID: {REPO_ID}")

# ì „ì—­ ë³€ìˆ˜
huggingfacehub = None
initial_agent = None
GLOBAL_TOOLS = ALL_TOOLS

def initialize_global_agent():
    """ì „ì—­ LLMê³¼ Toolì„ ì´ˆê¸°í™”"""
    global huggingfacehub, GLOBAL_TOOLS, initial_agent
    
    try:
        logger.info("ðŸš€ Initializing Global LLM and Tools...")
        
        if not HUGGINGFACE_TOKEN:
            raise ValueError("HUGGINGFACE_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # HuggingFace Endpoint LLM ì´ˆê¸°í™”
        huggingfacehub = HuggingFaceEndpoint(
            repo_id=REPO_ID,
            huggingfacehub_api_token=HUGGINGFACE_TOKEN,
            temperature=0.1,
            max_new_tokens=512,
            task="text2text-generation"
        )
        
        logger.info(f"âœ… Tools loaded: {[tool.name for tool in GLOBAL_TOOLS]}")
        
        initial_agent = True
        
        logger.info(f"âœ… LLM initialized: {REPO_ID}")
        logger.info(f"âœ… Total tools: {len(GLOBAL_TOOLS)}")
        
    except Exception as e:
        logger.error(f"âŒ LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        huggingfacehub = None
        initial_agent = False
        raise

def create_agent_executor(memory_instance: ConversationBufferMemory):
    """ì„¸ì…˜ë³„ Agent Executor ìƒì„± (ìƒˆë¡œìš´ API ì‚¬ìš©)"""
    if not huggingfacehub or not initial_agent:
        raise RuntimeError("LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    logger.info("ðŸ”§ Creating Agent Executor with memory...")
    
    # ReAct í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    from langchain.prompts import PromptTemplate
    
    template = """Answer the following questions as best you can. You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought:{agent_scratchpad}"""
    
    prompt = PromptTemplate.from_template(template)
    
    # ReAct Agent ìƒì„±
    agent = create_react_agent(
        llm=huggingfacehub,
        tools=GLOBAL_TOOLS,
        prompt=prompt
    )
    
    # Agent Executor ìƒì„± (output_keys ëª…ì‹œ)
    agent_executor = AgentExecutor(
        agent=agent,
        tools=GLOBAL_TOOLS,
        memory=memory_instance,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=5,
        return_intermediate_steps=False  # ðŸ‘ˆ ì¶”ê°€
    )
    
    # output_keys ëª…ì‹œì  ì„¤ì •
    agent_executor.output_keys = ["output"]  # ðŸ‘ˆ ì¶”ê°€
    
    logger.info("âœ… Agent Executor created successfully")
    
    return agent_executor

# ì„¸ì…˜ ë©”ëª¨ë¦¬ ìºì‹œ
SESSION_MEMORY_CACHE = {}

def cleanup_old_sessions(max_sessions: int = 1000):
    """ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬"""
    if len(SESSION_MEMORY_CACHE) > max_sessions:
        keys_to_delete = list(SESSION_MEMORY_CACHE.keys())[:len(SESSION_MEMORY_CACHE) // 2]
        for key in keys_to_delete:
            del SESSION_MEMORY_CACHE[key]
        logger.info(f"ðŸ§¹ Cleaned up {len(keys_to_delete)} old sessions")

GLOBAL_AGENT_EXECUTOR = None