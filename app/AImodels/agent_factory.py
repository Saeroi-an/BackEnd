# app/AImodels/agent_factory.py
import os
import logging
from supabase import Client

# LangChain ìµœì‹  ë²„ì „(1.x)ì—ì„œëŠ” ê¸°ì¡´ì˜ ì—ì´ì „íŠ¸ êµ¬í˜„(AgentExecutor, ReAct agent ë“±)ì´
# 'langchain' ë³¸ íŒ¨í‚¤ì§€ì—ì„œ ë¶„ë¦¬ë˜ì–´ 'langchain-classic' íŒ¨í‚¤ì§€ë¡œ ì´ë™í•œ ê²½ìš°ê°€ ë§ŽìŒ.
# ê¸°ì¡´ ì½”ë“œ(ë ˆê±°ì‹œ ReAct ì—ì´ì „íŠ¸)ë¥¼ ìœ ì§€í•˜ë ¤ë©´ classicì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²Œ ì•ˆì •ì .
from langchain_classic.agents import AgentExecutor
# â†‘ AgentExecutor: "Agent(ì¶”ë¡  ë¡œì§) + Tools(ë„êµ¬)"ë¥¼ ë¬¶ì–´ì„œ ì‹¤í–‰(invoke)í•  ìˆ˜ ìžˆê²Œ í•´ì£¼ëŠ” ì‹¤í–‰ê¸°
try:
    from langchain_classic.agents import create_react_agent
except ImportError:
    # ë²„ì „/ë°°í¬ í˜•íƒœì— ë”°ë¼ ìœ„ ê²½ë¡œë¡œ exportê°€ ì•ˆ ë˜ì–´ ìžˆì„ ìˆ˜ ìžˆìŒ -> ê·¸ëŸ´ ë• ì‹¤ì œ êµ¬í˜„ ìœ„ì¹˜(react.agent)ì—ì„œ ì§ì ‘ import.
    #  ì´ë ‡ê²Œ try/exceptë¡œ fallbackì„ ë‘ë©´ í™˜ê²½/ë²„ì „ì´ ì¡°ê¸ˆ ë‹¬ë¼ë„ ì„œë¹„ìŠ¤ê°€ ê¹¨ì§ˆ í™•ë¥ ì´ ë‚®ì•„ì§.
    from langchain_classic.agents.react.agent import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.tools import Tool
from langchain_core.prompts import PromptTemplate
from app.AImodels.tools import ALL_TOOLS

logger = logging.getLogger(__name__)


# ì „ì—­ ë³€ìˆ˜
GLOBAL_TOOLS = ALL_TOOLS
GLOBAL_LLM = None

def initialize_global_agent():
    """ì „ì—­ LLMê³¼ Toolì„ ì´ˆê¸°í™” (ë¡œì»¬ ëª¨ë¸)"""
    global GLOBAL_TOOLS, GLOBAL_LLM
    
    try:
        logger.info("ðŸš€ OpenAI ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
        
        # Initialize the language model with specific parameters
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.1,  # Low temperature for consistent reasoning
            max_tokens=2000,
            timeout=30
        )
        
        logger.info(f"âœ… global tools ì¶œë ¥ í™•ì¸: {GLOBAL_TOOLS}")
        logger.info(f"âœ… Tools loaded: {[tool.name for tool in GLOBAL_TOOLS]}")
        
        
        GLOBAL_LLM = llm
        
        logger.info(f"âœ… Total tools: {len(GLOBAL_TOOLS)}")
        
    except Exception as e:
        logger.error(f"âŒ OpenAI ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}")

        raise

# ì´ì œ Supabase ì§ì ‘ ì ‘ê·¼
def create_agent_executor(supabase: Client, user_id: str):  # ðŸ‘ˆ 1. íŒŒë¼ë¯¸í„° ë³€ê²½
    """ì„¸ì…˜ë³„ Agent Executor ìƒì„± (Memory ì—†ì´ Supabase ì§ì ‘ ì‚¬ìš©)"""
    global GLOBAL_LLM, GLOBAL_TOOLS
    
    if GLOBAL_LLM is None:
        logger.error("âŒ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        raise ValueError("LLM is not initialized.")
    
    logger.info(f"ðŸ”§ Creating Agent Executor for user: {user_id}")
    
    # ðŸ‘‡ 2. Supabaseì—ì„œ ì±„íŒ… ê¸°ë¡ ì¡°íšŒ: ì±„íŒ… ê¸°ë¡ ì§ì ‘ ì¡°íšŒ
    from app.services.chat_service import load_chat_history_from_db
    
    chat_history = load_chat_history_from_db(supabase, user_id, limit=6)
    chat_history_text = chat_history[0] if chat_history else ""
 
    # Create optimized prompt template # âœ… check
    react_prompt = PromptTemplate.from_template("""You are a helpful medical assistant. Answer questions based on the tools available and conversation history.

Available tools:
{ALL_TOOLS}

Tool Names: {tool_names}

Guidelines:
- If the question contains "prescription_id: [number]", use VL_Model_Image_Analyzer with that number as input 
- For drug information questions, use Public_Data_API_Searcher
- Otherwise, answer based on your knowledge

Use this format:
Question: the input question
Thought: think about what to do
Action: the tool to use (one of [{tool_names}]) OR say "No tool needed"
Action Input: the input for the tool (if using a tool)
Observation: the tool's response
... (repeat Thought/Action/Observation if needed)
Thought: I now know the final answer
Final Answer: the complete answer to the question

Begin!

Previous conversation:
{chat_history}

Question: {user_query}""")
    
    
    
    agent = create_react_agent(
        llm=GLOBAL_LLM,
        tools=GLOBAL_TOOLS,
        prompt=react_prompt
    )
    
    agent_executor = AgentExecutor(
        agent=agent,
        tools=GLOBAL_TOOLS,
        # memory=memory_instance, : memory íŒŒë¼ë¯¸í„° ì œê±°: ì±„íŒ… ê¸°ë¡ì´ ì´ë¯¸ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë¨ & LangChain Memory ì‹œìŠ¤í…œ ë¶ˆí•„ìš”
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=3 
    )
    
    logger.info("ReAct agent created successfully")
    
    # executor ê°ì²´ë§Œ ë°˜í™˜: invokeëŠ” chat_serviceì—ì„œ ì‹¤í–‰ & agent_factoryëŠ” ìƒì„±ë§Œ ë‹´ë‹¹
    # ai_response = agent_executor.invoke({"input": user_query})
    logger.info("âœ… Agent Executor created successfully")
    # logger.info(f"ëž­ì²´ì¸ì´ ìƒì„±í•œ ë‹µë³€: {ai_response}")
    
    # return ai_response # string
    return agent_executor

SESSION_MEMORY_CACHE = {}

def cleanup_old_sessions(max_sessions: int = 1000):
    """ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬"""
    if len(SESSION_MEMORY_CACHE) > max_sessions:
        keys_to_delete = list(SESSION_MEMORY_CACHE.keys())[:len(SESSION_MEMORY_CACHE) // 2]
        for key in keys_to_delete:
            del SESSION_MEMORY_CACHE[key]
        logger.info(f"ðŸ§¹ Cleaned up {len(keys_to_delete)} old sessions")

GLOBAL_AGENT_EXECUTOR = None