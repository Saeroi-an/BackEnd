# app/AImodels/agent_factory.py
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
from langchain_community.llms import HuggingFacePipeline
from langchain.agents import AgentExecutor, create_react_agent
from langchain.memory import ConversationBufferMemory
from langchain import hub  # ðŸ‘ˆ ì¶”ê°€
import torch
import os
import logging
from app.AImodels.tools import ALL_TOOLS

logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
REPO_ID = os.getenv('LLM_REPO_ID', 'google/flan-t5-large')

logger.info(f"ðŸ” LLM_REPO_ID: {REPO_ID}")

# ì „ì—­ ë³€ìˆ˜
huggingfacehub = None
initial_agent = None
GLOBAL_TOOLS = ALL_TOOLS

def initialize_global_agent():
    """ì „ì—­ LLMê³¼ Toolì„ ì´ˆê¸°í™” (ë¡œì»¬ ëª¨ë¸)"""
    global huggingfacehub, GLOBAL_TOOLS, initial_agent
    
    try:
        logger.info("ðŸš€ Initializing Global LLM and Tools (Local Model)...")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
        device = 0 if torch.cuda.is_available() else -1
        logger.info(f"ðŸ–¥ï¸ Using device: {'GPU' if device == 0 else 'CPU'}")
        
        # í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ
        tokenizer = AutoTokenizer.from_pretrained(REPO_ID)
        model = AutoModelForSeq2SeqLM.from_pretrained(
            REPO_ID,
            torch_dtype=torch.float16 if device == 0 else torch.float32,
            device_map="auto" if device == 0 else None
        )
        
        # Pipeline ìƒì„±
        pipe = pipeline(
            "text2text-generation",
            model=model,
            tokenizer=tokenizer,
            max_new_tokens=512,
            temperature=0.1
        )
        
        # LangChain LLMìœ¼ë¡œ ëž˜í•‘
        huggingfacehub = HuggingFacePipeline(pipeline=pipe)
        
        logger.info(f"âœ… Tools loaded: {[tool.name for tool in GLOBAL_TOOLS]}")
        
        initial_agent = True
        
        logger.info(f"âœ… LLM initialized (Local): {REPO_ID}")
        logger.info(f"âœ… Total tools: {len(GLOBAL_TOOLS)}")
        
    except Exception as e:
        logger.error(f"âŒ LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        huggingfacehub = None
        initial_agent = False
        raise

def create_agent_executor(memory_instance: ConversationBufferMemory):
    """ì„¸ì…˜ë³„ Agent Executor ìƒì„±"""
    if not huggingfacehub or not initial_agent:
        raise RuntimeError("LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    logger.info("ðŸ”§ Creating Agent Executor with memory...")
    
    # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    from langchain.prompts import PromptTemplate
    
    template = """You are a helpful medical assistant. Answer questions based on the tools available and conversation history.

Available tools:
{tools}

Tool Names: {tool_names}

Guidelines:
- If the question contains "prescription_id: [number]", use VL_Model_Image_Analyzer with that number as input
- For drug information questions, use Public_Data_API_Searcher
- Otherwise, answer based on your knowledge

Use this format:
Question: the input question
Thought: think about what to do
Action: the tool to use (one of [{tool_names}]) OR say "No tool needed"
Action Input: the input for the tool (if using a tool)
Observation: the tool's response
... (repeat Thought/Action/Observation if needed)
Thought: I now know the final answer
Final Answer: the complete answer to the question

Begin!

Previous conversation:
{chat_history}

Question: {input}
{agent_scratchpad}"""
    
    prompt = PromptTemplate.from_template(template)
    
    agent = create_react_agent(
        llm=huggingfacehub,
        tools=GLOBAL_TOOLS,
        prompt=prompt
    )
    
    agent_executor = AgentExecutor(
        agent=agent,
        tools=GLOBAL_TOOLS,
        memory=memory_instance,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=3  # ðŸ‘ˆ iteration ì œí•œ ì¤„ìž„
    )
    
    logger.info("âœ… Agent Executor created successfully")
    
    return agent_executor

SESSION_MEMORY_CACHE = {}

def cleanup_old_sessions(max_sessions: int = 1000):
    """ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬"""
    if len(SESSION_MEMORY_CACHE) > max_sessions:
        keys_to_delete = list(SESSION_MEMORY_CACHE.keys())[:len(SESSION_MEMORY_CACHE) // 2]
        for key in keys_to_delete:
            del SESSION_MEMORY_CACHE[key]
        logger.info(f"ðŸ§¹ Cleaned up {len(keys_to_delete)} old sessions")

GLOBAL_AGENT_EXECUTOR = None